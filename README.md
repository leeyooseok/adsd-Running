# 자율주행 데이터 학습&주행

------------------------------------------------------------------
## myjoystick.py

- PyQt5를 사용하여 joystick 위젯을 구현한 것으로 사용자가 마우스로 조이스틱을 조작하여 X,Y 축의 좌표를 전송해줍니다.
- 조이스틱의 움직임을 원활하게 하기 위해 GUI를 구성하는 역할을 하였고 마우스의 입력을 받아 드래그 및 클릭 이벤트를 처리할 수 있도록 했습니다.<br>
- 조이스틱의 움직임 좌표는 joystick.py코드에서 실행하여 쉘에서 확인가능합니다.
- 
## joystick.py
![KakaoTalk_20240913_122123160](https://github.com/user-attachments/assets/90215bb3-9bff-4866-94bc-bdbd614ec11c)

- 위젯의 위치와 배경 색을 지정하고 이 위젯에 레이아웃을 설정해 조이스틱, 비디오 라벨, 속도 슬라이더를 배치합니다.
- MyJoystick 클래스를 사용해 Joystick을 생성하고, cbJoyPos 콜백 함수를 통해 Joystick의 위치를 출력합니다.
이 콜백 함수는 Joystick의 좌표를 받아서 print를 통해 콘솔에 출력합니다.
- QSlider를 사용해 수평 슬라이더를 구현하고, 슬라이더 값이 변경될 때마다 valueChanged 시그널을 통해 현재 값을 출력합니다.<br>
슬라이더는 속도를 나타내며 범위는 0에서 100까지로 설정되어 있으며, 10 단위로 표시되도록 하였습니다.

-------------------------------------------------------------------------------------------------

## myjoystickapp.py

- myjoystickapp은 조이스틱,슬라이더,비디오 라벨 등 여러 UI 요소를 포함한 애플리케이션입니다.
- 애플리케이션의 실행과 전체적인 UI 구성을 관리하고 조이스틱과 다른 위젯을 연동하여 하나의 통합된 프로그램을 구성합니다.
-joystick과 myjoystickapp 파일의 형태가 비슷해보이지만 MyJoystick은 Joystick 자체의 기능을 정의한 작은 단위의 클래스이고, MyJoystickApp은 Joystick과 다른 요소들을 포함한 전체 프로그램을 구성하는 클래스입니다.

## joystick_pos.py

![KakaoTalk_20240913_155425257](https://github.com/user-attachments/assets/3cd0a921-20c0-497b-8be3-48c6f41bb526)

- joystick_pos은 위의 myjoystickapp을 동작시키는 역할을 합니다.
- ```cbJoyPos(joystickPosition, app)``` 함수는 조이스틱의 현재 위치 좌표와 속도 정보를 출력하는 콜백입니다.

## joystick_dir.py

![KakaoTalk_20240913_170249743](https://github.com/user-attachments/assets/0f04895f-8bd3-4d39-bbdb-054d6969f0b6)


- joystick_dir은 위에 방식과 유사하지만 좌표를 나누어 방향을 출력하도록 하였습니다.
- 방향으로 바꾸어 출력하여 움직임에 따른 구분이 쉬워졌으며 데이터를 쌓을때 편리성을 높혔습니다.

------------------------------------------------------------------------------------------

## MyJoystickCamApp.py

- MyJoystickCamApp은 MyJoystickApp을 확장하여, 자율주행 RC 카의 실시간 비디오 스트리밍과 프레임 속도를 처리하는 기능을 추가한 애플리케이션입니다.
- 이 클래스는 OpenCV를 사용하여 비디오 스트림을 받아와 PyQt5 인터페이스에 출력하며, 프레임 속도를 실시간으로 계산해 출력합니다.
- 데이터를 쌓기 위해 영상을 스트리밍 받아오는 것이 중요하며 영상을 잘 출력되야 데이터를 쌓을때 변수를 줄일 수 있습니다.

## video_joystick.py

![화면 캡처 2024-09-13 180243](https://github.com/user-attachments/assets/97dfffa6-a14f-49be-88c8-4d0727e8c2d8)

- video_joystick은 MyJoystickCamApp를 기반으로 조이스틱을 이용한 자동차 제어와 실시간 비디오 스트리밍을 결합한 프로그램입니다.
- 조이스틱을 이용하여 RC카의 방향을 제어하며 실시간 비디오 피드를 제공합니다.

## MyJoystickCamApp.py

- MyDataCollectionApp은 MyJoystickCamApp을 상속받아 조이스틱과 카메라 입력을 활용하여 데이터를 수집하는 역할을 합니다.
- 조이스틱의 위치에 따라 프레임을 수집하고 수집한 데이터를 특정 디렉토리에 저장하는 기능을 제공합니다.
- 디렉토리는 forward,right,left,stop으로 나뉘며 앞서 쉘에 나타나는 결과값에 따라 저장이 되도록 합니다.

## _02_video_joystick_data_collection.py

![KakaoTalk_20240919_121931055](https://github.com/user-attachments/assets/84304e10-b085-480b-a5d1-b8591baf107f)

- _02_video_joystick_data_collection은  MyDataCollectionApp을 사용하여 Joystick과 모터 제어를 결합한 애플리케이션입니다.
Joystick의 입력을 받아 RC 카와 같은 장치를 제어하고, 동시에 데이터를 수집하는 기능을 구현하고 있습니다.
- ```mot_serial.write(command.encode())```를 통해 결정된 명령(f, r, l, s)을 아두이노 시리얼 통신으로 모터에 전송합니다. 이를 통해 Joystick 입력에 따라 모터가 RC 카의 움직임을 제어하게 됩니다.
- 위의 사진처럼 움직임에 따른 데이터가 분류되어 디렉토리에 저장됩니다.

## _03_data_labelling.py
  
![KakaoTalk_20240919_130133494](https://github.com/user-attachments/assets/7fbd6aa3-2846-431a-b370-e75f4d0efaef)

  - _03_data_labelling은 데이터 디렉터리 내의 파일을 탐색하여, 각 파일의 경로와 레이블 정보를 CSV 파일로 저장하는 작업을 수행합니다. 데이터 수집 후, 이를 레이블링하여 머신러닝 모델에 사용하기 위한 데이터를 준비하는 과정으로 볼 수 있습니다.
  - 머신러닝 모델 학습을 위한 데이터 전처리 과정에서, 수집된 데이터를 체계적으로 정리하고, 이를 모델이 학습할 수 있는 형태로 변환하는 작업을 수행했습니다.<br>
  특히, 대규모 데이터를 다루는 자율주행 프로젝트에서 각 데이터의 라벨링과 정리 작업은 모델의 성능에 직접적인 영향을 미치므로 중요한 단계입니다.

## _04_cnn_training_1.py

![1](https://github.com/user-attachments/assets/25782f35-e039-4d5d-837c-f5c21408e42e)

- _04_cnn_training_1는 머신러닝 모델에서 학습할 수 있도록, 이미지 데이터를 텐서로 변환하는 **데이터 전처리** 작업을 수행합니다.
- CSV 파일에서 이미지 파일 경로와 라벨을 불러오고, 이미지를 텐서로 변환하여 모델 학습에 사용할 수 있는 형태로 정리합니다.
- TensorFlow의 Keras API를 사용해 이미지를 배열로 변환하고, 모델 학습을 위한 입력 형식으로 준비하는 과정입니다.
- 데이터 셔플링을 통해 학습 중 데이터 편향을 방지하고, 모델 성능을 향상시키는 전처리작업을 수행하였습니다.

## _04_cnn_training_2.py

![2](https://github.com/user-attachments/assets/e50db1e8-e76c-472d-80e3-316c7a219b37)

- _04_cnn_training_2는 **이미지 시각화**를 통해 학습 데이터의 샘플을 확인하는 작업을 수행합니다.
- 이미지를 불러와 OpenCV와 Matplotlib를 사용하여 시각화하고, 각 이미지의 제목에 해당 레이블을 표시합니다. 주로 데이터 확인과 모델 학습 전 데이터 품질 평가에 사용됩니다.

## _04_cnn_training_3.py

![3](https://github.com/user-attachments/assets/afc90571-fcb7-4f44-b1c1-374dfe415923)

- 총 데이터: 3977개의 이미지가 있으며, 각 이미지는 120x160의 RGB 이미지고, 각 데이터는 원-핫 인코딩된 4개의 클래스 중 하나에 속합니다.
- 데이터 분할
  - 훈련 데이터: 3181개 (80%)
  - 검증 데이터: 398개 (10%)
  - 테스트 데이터: 398개 (10%)

- 머신러닝 모델의 학습 성능을 높이기 위해 **이미지 데이터를 정규화**하였습니다. 이를 통해 각 이미지의 픽셀 값을 0~1 사이의 값으로 변환하여, 모델이 효율적으로 데이터를 처리할 수 있도록 하였습니다. 데이터는 float32 형식으로 변환하고, 픽셀 값을 255로 나누어 스케일링하였습니다.
- 분류 문제를 해결하기 위해 레이블을 **원-핫 인코딩**으로 변환하였습니다. 이를 통해 각 레이블은 벡터로 표현되었으며, 총 4개의 클래스를 0과 1로 이루어진 원-핫 벡터로 변환하여 모델의 출력과 매칭할 수 있도록 처리하였습니다.
- 학습 데이터와 테스트 데이터를 분리하여, 모델이 학습 중 과적합되지 않도록 관리하였습니다.
- 데이터 분할 시, random_state 값을 고정하여 데이터 분할의 재현성을 확보하였습니다. 이를 통해 동일한 데이터셋에서 일관된 실험 결과를 유지할 수 있었으며, 실험 반복 시에도 동일한 결과를 도출할 수 있었습니다.

### *원-핫 인코딩이란*

- 범주형(카테고리) 데이터를 숫자 벡터로 변환하는 방법
- 머신러닝 모델, 특히 신경망 모델에서 분류 작업을 수행할 때, 범주형 데이터를 숫자로 표현하여 모델이 처리할 수 있도록 변환하는 과정이 필요합니다.

## _04_cnn_training_4.py

![55](https://github.com/user-attachments/assets/e730a793-d8c7-488c-9fb7-c8af8f6cf0b9)
![11](https://github.com/user-attachments/assets/8b1d8e04-7d0c-4f8d-b584-2c053b94979e)


- _04_cnn_training_4는 딥러닝 CNN 모델을 정의하고 학습시키는 전체적인 과정을 설명하는 코드입니다. CNN을 활용해 이미지 데이터를 처리하며, 학습 과정에서 손실 함수를 모니터링하고, 최종적으로 모델을 저장하는 과정을 포함하고 있습니다.
- 컨볼루션 신경망(CNN) 모델을 tf.keras.Sequential로 구성합니다. 이 CNN 모델은 이미지 데이터를 처리하고 분류하는 데 사용되고 모델의 각 층은 다음과 같은 역할을 합니다.
  - **Conv2D 레이어**: 2D 컨볼루션 필터를 사용해 이미지의 특징을 추출합니다. 처음에는 24개의 필터를 사용하고, 점점 더 많은 필터(32, 64)로 이미지를 처리하여 더 깊은 특징을 학습합니다.
  - **Dropout 레이어**: 과적합 방지를 위해 일부 노드를 무작위로 끄는 레이어로, 학습 중 노드의 일부를 비활성화하여 모델의 일반화 성능을 향상시킵니다.
  - **Flatten 레이어**: CNN에서 추출한 2D 데이터를 1D로 펼쳐 **완전 연결층(Dense Layer)**에 전달하기 위한 단계입니다.
  - **Dense 레이어**: 완전 연결층으로, 마지막에 softmax 활성화 함수를 사용해 4개의 클래스(전진, 좌회전, 우회전, 정지) 중 하나를 예측합니다.
- Categorical Crossentropy 손실 함수와 Adam Optimizer를 사용해 모델을 컴파일하고, 정확도(Accuracy) 지표를 기반으로 학습 성능을 평가했습니다. 총 50번의 에포크를 거쳐 모델을 학습시켰으며, 훈련 데이터와 검증 데이터를 이용해 학습 도중 과적합 여부를 평가했습니다.
- 학습 과정에서의 손실 값 변화를 Matplotlib로 시각화하여, 각 에포크마다 손실이 감소하는 경향을 파악했습니다. 이를 통해 모델이 점진적으로 성능을 개선하는지, 또는 과적합이 발생하는지 분석할 수 있었습니다.
- 학습이 완료된 모델을 .keras 파일로 저장하여 나중에 예측이나 추가 학습을 위해 쉽게 불러올 수 있도록 하였습니다. 이 과정을 통해 모델 재사용 가능성을 확보하고, 실무에서의 효율성을 높혔습니다.
